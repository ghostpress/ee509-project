---
title: "EE 509 Project: Preliminary Analysis"
author: "Lucia Vilallonga"
output: html_document
---

# Background

Objective: describe and determine factors for adoption of residential rooftop solar systems in Massachusetts towns.

Models to fit:  (1) Bayesian GLM with Poisson; (2) Bayesian single linear regression; (3) Bayesian single linear regression with errors in variables; (4) time-series analysis (extra).

# Setup
## Libraries
```{r, echo=FALSE}
library(sf)             ## GIS data
library(rjags)          ## MCMC
library(LaplacesDemon)  ## WAIC
library(MCMCvis)        ## Visualize MCMC outputs for particular params
library(pdftools)       ## convert MCMCvis PDF output to image
library(imager)         ## show images from file
```

## Load and Format Data
```{r}
X <- st_read("/home/lucia/bu/year4/semester2/EE509/project/ee509-project/data/ready/X/X.shp")
y <- read.csv("/home/lucia/bu/year4/semester2/EE509/project/ee509-project/data/ready/y/y.csv")

# Join the datasets along the town axis
PV <- merge(X, y, by="TOWN")

# Format data for MCMC
# First models will not include spatial variables
# For now, just use the average income and education values (not sum/highest) and %Biden as covariates
dat <- list(y=PV$totalInst, x1=PV$avgEd, x2=PV$avgInc, x3=PV$Biden.)
```

Which variables are correlated with adoption?
```{r}
pairs(dat)

plot(dat$x1, dat$x2,
     main="Correlation Between Education and Income",
     xlab="Education", ylab="Income")

plot(dat$x1, dat$x3,
     main="Correlation Between Education and %Biden",
     xlab="Education", ylab="%Biden")

plot(dat$x2, dat$x3,
     main="Correlation Between Income and %Biden",
     xlab="Income", ylab="%Biden")

plot(dat$x3, dat$y,
     main="Correlation Between %Biden and Rooftop PV Adoptions",
     xlab="%Biden", ylab="N adoptions")
```

# Model 1: Bayesian GLM with Poisson regression

Process model:
$$log(\lambda_i) = \boldsymbol{\beta} X_i$$
Data model:
$$y_i \sim Pois(\lambda_i)$$
Parameter model:
$$\beta \sim Normal(B_0, V_b)$$
Log-likelihood:
$$ln(L) = \sum_{i=1}^n y_i(\beta X_i) - \sum_{i=1}^ne^{\beta X_i}$$

## Specify Model
```{r}
poisson_glm <- "
model {
  beta[1] ~ dnorm(B01, Vb1)  ## prior on beta 1
  beta[2] ~ dnorm(B02, Vb2)  ## prior on beta 2

  for(i in 1:n) {
    log(lambda[i]) <- beta[1] + beta[2]*x[i]    ## process model
    y[i] ~ dpois(lambda[i])                     ## data model 
    log(like[i]) <- y[i]*lambda[i] - exp(lambda[i])  ## log-likelihoods
  }
}"
```

```{r}
datap <- list(y=dat$y, x=dat$x3)

# Specify priors
datap$B01 <- 0      ## priors on B1 means
datap$B02 <- 0      ## priors on B2 means
datap$Vb1 <- 0.001  ## priors on B1 variances
datap$Vb2 <- 0.001  ## priors on B2 variances
datap$n   <- length(datap$y)  ## n = no. of observations; m = no. of covariates

# Initialize JAGS
j.pois <- jags.model(file=textConnection(poisson_glm),
                       data=datap, 
                       n.chains=3)
```

```{r}
# Run JAGS
jags.pois <- coda.samples(model=j.pois, 
                          variable.names=c("beta[1]", "beta[2]", "like"),
                          n.iter=70000)  ## 90000 had good convergence but memory issues
```

## Splitting JAGS output
Code source: Michael Dietze
```{r}
# Function to split JAGS output
codaSplit <- function(jags.out,pattern){
  out = list()
  mfit = as.matrix(jags.out,chains=TRUE)
  pat.cols = grep(pattern,colnames(mfit),fixed=TRUE)
  chain.col = which(colnames(mfit)=="CHAIN")
  out[[1]] = mat2mcmc.list(mfit[,c(chain.col,pat.cols)])
  out[[2]]   = mat2mcmc.list(mfit[,-pat.cols])
  return(out)
}

mat2mcmc.list <- function(w) {
  temp <- list()
  chain.col <- which(colnames(w) == "CHAIN")
  for (i in unique(w[, "CHAIN"])) {
    temp[[i]] <- coda:::as.mcmc(w[w[, "CHAIN"] == i, -chain.col])
  }
  return(as.mcmc.list(temp))
}
```

## Diagnostics
```{r}
# Split JAGS object (don't want to plot traces for the likelihoods)
pois_split <- codaSplit(jags.pois, "like")

# Trace plots
plot(pois_split[[2]])

# Brooks-Gelman-Rubin
GBR <- gelman.plot(pois_split[[2]])

# Remove burn-in
jags.burn_pois <- window(jags.pois, start=5000)
burn_pois_split <- codaSplit(jags.burn_pois, "like")

# Checking convergence & posterior densities, GBR for burn-in
plot(burn_pois_split[[2]])
GBR <- gelman.plot(burn_pois_split[[2]])

out_burn_pois_split <- as.matrix(burn_pois_split[[2]]) 

# Effective sample size
effectiveSize(out_burn_pois_split)  

# Conclusions: burn-in does not improve GBR, convergence, or effective size
# Use initial outputs instead
```

## Density plots
```{r}
plot(density(out_burn_pois_split[, "beta[1]"]), main="Intercept", 
     sub="Density of MCMC samples for intercept term (Poisson model)", cex.sub=0.8) 
plot(density(out_burn_pois_split[,"beta[2]"]), main="Beta[2]", 
     sub="Density of MCMC samples for slope term (Poisson model)", cex.sub=0.8)  
```

## Model Fit
```{r}
# DIC
dic.pois <- dic.samples(j.pois, 1000, "pD")
dic.pois <- sum(dic.pois$deviance) + sum(dic.pois$penalty)

# WAIC
waic.pois <- WAIC(as.matrix(pois_split[[1]]))

print(paste("DIC: ", round(dic.pois, digits=3), " WAIC: ", round(waic.pois$WAIC, digits=3)))
```

## Parameter Confidence Intervals
```{r}
c1.pois <- quantile(out_burn_pois_split[,"beta[1]"], c(0.025, 0.975))  ## beta[1] (intercept)
c2.pois <- quantile(out_burn_pois_split[,"beta[2]"], c(0.025, 0.975))  ## beta[2] (slope on x3, %Biden)
```

## Credible Interval Plots
```{r}
niter <- 10000
xpred <- seq(0.3, 1.0, length=50)
npred <- length(xpred)

ypred <- matrix(NA, nrow=niter, ncol=npred)
ycred <- matrix(NA, nrow=niter, ncol=npred)

for(i in 1:niter){
  Ey  <- exp(out_burn_pois_split[i, 1] + out_burn_pois_split[i, 2]*xpred)
  ycred[i,] <- Ey
  ypred[i,] <- rpois(npred, Ey)
}

ci <- apply(ycred, 2, quantile, c(0.025, 0.975))  
pi <- apply(ypred, 2, quantile, c(0.025, 0.975))

plot(datap$x, datap$y, 
     main="CI, PI Plots for Bayesian Poisson model",
     xlab="x3, %Biden",
     ylab="N, adoptions")

lines(xpred, ci[1,], col=3, lty=2)
lines(xpred, ci[2,], col=3, lty=2)

lines(xpred, pi[1,], col=2, lty=2)
lines(xpred, pi[2,], col=2, lty=2)

legend(0.4, 800, legend=c("CI", "PI"), col=c(3, 2), lty=2, cex=0.8)
```


# Model 2: Bayesian single linear regression 
The results from models S and Sa, as well as the pairs plot, suggest that x3, %Biden, might be the only contributing covariate to residential rooftop PV adoption. Test that by trying a simple Bayesian linear regression with x3 as the sole covariate:

## Specify model
```{r}
linear_glm_x3 <- "
model {
  beta[1] ~ dnorm(B01, Vb1)
  beta[2] ~ dnorm(B02, Vb2)
  S ~ dgamma(s1, s2)      ## prior on precision
  
  for(i in 1:n) {
    mu[i] <- beta[1] + beta[2]*x[i]
    y[i] ~ dnorm(mu[i], S)
    like[i] <- dnorm(y[i], mu[i], S)
  }
}"
```

## MCMC Setup
```{r}
data1 <- list(y=dat$y, x=dat$x3)

# Specify priors
data1$B01 <- 0      ## priors on B1 means
data1$B02 <- 0      ## priors on B2 means
data1$Vb1 <- 0.001  ## priors on B1 variances
data1$Vb2 <- 0.001  ## priors on B2 variances
data1$s1  <- 0.001
data1$s2  <- 0.001
data1$n  <- length(data1$y) ## n = no. of observations; m = no. of covariates

# Initialize JAGS
j.lin_x3 <- jags.model(file=textConnection(linear_glm_x3),
                       data=data1, 
                       n.chains=3)
```

## Run MCMC
```{r}
# Run JAGS
jags.lin_x3 <- coda.samples(model=j.lin_x3, 
                          variable.names=c("beta[1]", "beta[2]", "S", "like"),
                          n.iter=30000)
```

## Diagnostics
```{r}
# Split MCMC output
lin_x3_split <- codaSplit(jags.lin_x3, "like")
plot(lin_x3_split[[2]])

# Remove burn-in
jags.burn_lin_x3 <- window(jags.lin_x3, start=2000)
out_burn_lin_x3  <- as.matrix(jags.burn_lin_x3) 
burn_lin_x3_split <- codaSplit(jags.burn_lin_x3, "like")

# Checking convergence & posterior densities
plot(burn_lin_x3_split[[2]])

# Brooks-Gelman-Rubin
GBR <- gelman.plot(burn_lin_x3_split[[2]])

# Effective sample size
effectiveSize(burn_lin_x3_split[[2]])
```

## Density plots
```{r}
out_lin_x3_split <- as.matrix(burn_lin_x3_split[[2]])

plot(density(out_lin_x3_split[,1]), main="Intercept", 
     sub="Density of MCMC samples for intercept term (linear model)", cex.sub=0.8) 
plot(density(out_lin_x3_split[,2]), main="Beta[1]", 
     sub="Density of MCMC samples for slope on %Biden term (linear model)", cex.sub=0.8)  
```

## Model Fit
```{r}
# DIC
dic.lin_x3 <- dic.samples(j.lin_x3, 1000, "pD")
dic.lin_x3 <- sum(dic.lin_x3$deviance) + sum(dic.lin_x3$penalty)

# WAIC
waic.lin_x3 <- WAIC(as.matrix(lin_x3_split[[1]]))

print(paste("DIC: ", round(dic.lin_x3, digits=3), " WAIC: ", round(waic.lin_x3$WAIC, digits=3)))
```

## Parameter Confidence Intervals
```{r}
cS.lin_x3 <- quantile(out_burn_lin_x3[,"S"], c(0.025, 0.975))        ## S 
c1.lin_x3 <- quantile(out_burn_lin_x3[,"beta[1]"], c(0.025, 0.975))  ## beta[1] (intercept)
c2.lin_x3 <- quantile(out_burn_lin_x3[,"beta[2]"], c(0.025, 0.975))  ## beta[2] (slope on x3, %Biden)
```

## Credible and Predictive Interval Plots
***REDO PLOT***
```{r}
niter <- 10000
xpred <- seq(0.3, 1.0, length=50)
npred <- length(xpred)

ypred <- matrix(NA, nrow=niter, ncol=npred)
ycred <- matrix(NA, nrow=niter, ncol=npred)

for(i in 1:niter) {
  Ey <- out_burn_lin_x3[i, "beta[1]"] + out_burn_lin_x3[i, "beta[2]"]*xpred
  ycred[i,] <- Ey
  ypred[i,] <- rnorm(npred, Ey, out_burn_lin_x3[, "S"])
}

ci.x3 <- apply(ycred, 2, quantile, c(0.025, 0.975), na.rm=TRUE)
pi.x3 <- apply(ypred, 2, quantile, c(0.025, 0.975), na.rm=TRUE)

plot(data1$x, data1$y,
     main="CI, PI Plots for Bayesian linear model",
     xlab="x3, %Biden",
     ylab="N, adoptions")

lines(xpred, ci.x3[1,], col=3, lty=2)
lines(xpred, ci.x3[2,], col=3, lty=2)

lines(xpred, pi.x3[1,], col=2, lty=2)
lines(xpred, pi.x3[2,], col=2, lty=2)

legend(0.4, 800, legend=c("CI", "PI"), col=c(3, 2), lty=2, cex=0.8)
```

# Results

## Summary tables: models 1,2
```{r}
params <- c("S", "beta[1]", "beta[2]")

model1_vals <- c(NA, 
                 mean(out_burn_pois_split[,"beta[1]"]),
                 mean(out_burn_pois_split[,"beta[2]"]))
model2_vals <- c(mean(out_burn_lin_x3[,"S"]), 
                 mean(out_burn_lin_x3[,"beta[1]"]),
                 mean(out_burn_lin_x3[,"beta[2]"]))

model1_ci_l <- c(NA, c1.pois[1], c2.pois[1])
model1_ci_u <- c(NA, c1.pois[2], c2.pois[2])
model2_ci_l <- c(cS.lin_x3[1], c1.lin_x3[1], c2.lin_x3[1])
model2_ci_u <- c(cS.lin_x3[2], c1.lin_x3[2], c2.lin_x3[2])

res_df <- data.frame(params, model1_vals, model2_vals,
                     model1_ci_l, model1_ci_u, 
                     model2_ci_l, model2_ci_u)

crit    <- c("DIC", "WAIC")
fit_model1 <- c(dic.pois, waic.pois$WAIC)
fit_model2 <- c(dic.lin_x3, waic.lin_x3$WAIC)

fit_df <- data.frame(crit, fit_model1, fit_model2)

knitr::kable(res_df, caption="Parameter values for models 1 and 2")

knitr::kable(fit_df, caption="DIC and WAIC values for models 1 and 2")
```