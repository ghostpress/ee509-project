---
title: "EE 509 Project: Preliminary Analysis"
author: "Lucia Vilallonga"
output: html_document
---

# Background

Objective: describe and determine factors for adoption of residential rooftop solar systems in Massachusetts towns.

Models to fit:  (1) Bayesian GLM with Poisson; (2) Bayesian single linear regression; (3) Bayesian single linear regression with errors in variables; (4) time-series analysis (extra).

# Setup
## Libraries
```{r, echo=FALSE}
library(sf)             ## GIS data
library(rjags)          ## MCMC
library(LaplacesDemon)  ## WAIC
#library(MCMCvis)        ## Visualize MCMC outputs for particular params
#library(pdftools)       ## convert MCMCvis PDF output to image
#library(imager)         ## show images from file
```

## Load and Format Data
```{r}
X <- st_read("/home/lucia/bu/year4/semester2/EE509/project/ee509-project/data/ready/X/X.shp")
y <- read.csv("/home/lucia/bu/year4/semester2/EE509/project/ee509-project/data/ready/y/y.csv")

# Join the datasets along the town axis
PV <- merge(X, y, by="TOWN")

# Format data for MCMC
# First models will not include spatial variables
# For now, just use the average income and education values (not sum/highest) and %Biden as covariates
dat <- list(y=PV$totalInst, x1=PV$avgEd, x2=PV$avgInc, x3=PV$Biden.)
```

Which variables are correlated with adoption?
```{r}
pairs(dat)

plot(dat$x1, dat$x2,
     main="Correlation Between Education and Income",
     xlab="Education", ylab="Income")

plot(dat$x1, dat$x3,
     main="Correlation Between Education and %Biden",
     xlab="Education", ylab="%Biden")

plot(dat$x2, dat$x3,
     main="Correlation Between Income and %Biden",
     xlab="Income", ylab="%Biden")

plot(dat$x3, dat$y,
     main="Correlation Between %Biden and Rooftop PV Adoptions",
     xlab="%Biden", ylab="N adoptions")
```

# Model 1: Bayesian GLM with Poisson regression

Process model:
$$log(\lambda_i) = \boldsymbol{\beta} X_i$$
Data model:
$$y_i \sim Pois(\lambda_i)$$
Parameter model:
$$\beta \sim Normal(B_0, V_b)$$
Log-likelihood:
$$ln(L) = \sum_{i=1}^n y_i(\beta X_i) - \sum_{i=1}^ne^{\beta X_i}$$

## Specify Model
```{r}
poisson_glm <- "
model {
  beta[1] ~ dnorm(B01, Vb1)  ## prior on beta 1
  beta[2] ~ dnorm(B02, Vb2)  ## prior on beta 2

  for(i in 1:n) {
    log(lambda[i]) <- beta[1] + beta[2]*x[i]    ## process model
    y[i] ~ dpois(lambda[i])                     ## data model 
    like[i] <- y[i]*log(lambda[i]) - lambda[i]  ## log-likelihoods
  }
}"
```

```{r}
datap <- list(y=dat$y, x=dat$x3)

# Specify priors
datap$B01 <- 0      ## priors on B1 means
datap$B02 <- 0      ## priors on B2 means
datap$Vb1 <- 0.001  ## priors on B1 variances
datap$Vb2 <- 0.001  ## priors on B2 variances
datap$n   <- length(datap$y)  ## n = no. of observations; m = no. of covariates

# Initialize JAGS
j.pois <- jags.model(file=textConnection(poisson_glm),
                       data=datap, 
                       n.chains=3)
```

```{r}
# Run JAGS
jags.pois <- coda.samples(model=j.pois, 
                          variable.names=c("beta[1]", "beta[2]", "like"),
                          n.iter=70000)  ## 90000 had good convergence but memory issues
```

## Splitting JAGS output
Code source: Michael Dietze
```{r}
# Function to split JAGS output
codaSplit <- function(jags.out,pattern){
  out = list()
  mfit = as.matrix(jags.out,chains=TRUE)
  pat.cols = grep(pattern,colnames(mfit),fixed=TRUE)
  chain.col = which(colnames(mfit)=="CHAIN")
  out[[1]] = mat2mcmc.list(mfit[,c(chain.col,pat.cols)])
  out[[2]]   = mat2mcmc.list(mfit[,-pat.cols])
  return(out)
}

mat2mcmc.list <- function(w) {
  temp <- list()
  chain.col <- which(colnames(w) == "CHAIN")
  for (i in unique(w[, "CHAIN"])) {
    temp[[i]] <- coda:::as.mcmc(w[w[, "CHAIN"] == i, -chain.col])
  }
  return(as.mcmc.list(temp))
}
```

## Diagnostics
```{r}
# Split JAGS object (don't want to plot traces for the likelihoods)
pois_split <- codaSplit(jags.pois, "like")

# Trace plots
plot(pois_split[[2]])

# Brooks-Gelman-Rubin
GBR <- gelman.plot(pois_split[[2]])

# Remove burn-in
jags.burn_pois <- window(jags.pois, start=5000)
burn_pois_split <- codaSplit(jags.burn_pois, "like")

# Checking convergence & posterior densities, GBR for burn-in
plot(burn_pois_split[[2]])
GBR <- gelman.plot(burn_pois_split[[2]])

# Effective sample size
effectiveSize(pois_split[[2]])  

# Conclusions: burn-in does not improve GBR, convergence, or effective size
# Use initial outputs instead
```

## Density plots
```{r}
out_pois_split <- as.matrix(pois_split[[2]])

plot(density(out_pois_split[,1]), main="Intercept", 
     sub="Density of MCMC samples for intercept term (Poisson model)", cex.sub=0.8) 
plot(density(out_pois_split[,2]), main="Beta[1]", 
     sub="Density of MCMC samples for slope term (Poisson model)", cex.sub=0.8)  
```

## Credible Interval Plots
```{r}
niter <- 10000
xpred <- seq(0.3, 1.0, length=50)
npred <- length(xpred)

ypred <- matrix(NA, nrow=niter, ncol=npred)
ycred <- matrix(NA, nrow=niter, ncol=npred)

for(i in 1:niter){
  Ey  <- exp(out_pois_split[i, 1] + out_pois_split[i, 2]*xpred)
  ycred[i,] <- Ey
  ypred[i,] <- rpois(npred, Ey)
}

ci <- apply(ycred, 2, quantile, c(0.025, 0.975))  
pi <- apply(ypred, 2, quantile, c(0.025, 0.975))

plot(datap$x, datap$y, 
     main="CI, PI Plots for Bayesian Poisson Model",
     xlab="x3, %Biden",
     ylab="N, adoptions")

lines(xpred, ci[1,], col=3, lty=2)
lines(xpred, ci[2,], col=3, lty=2)

lines(xpred, pi[1,], col=2, lty=2)
lines(xpred, pi[2,], col=2, lty=2)

legend(0.4, 800, legend=c("CI", "PI"), col=c(3, 2), lty=2, cex=0.8)
```

## Model Fit
```{r}
# DIC
dic.pois <- dic.samples(j.pois, 1000, "pD")
dic.pois <- sum(dic.pois$deviance) + sum(dic.pois$penalty)

# WAIC
waic.pois <- WAIC(as.matrix(pois_split[[1]]))

print(paste("DIC: ", round(dic.pois, digits=3), " WAIC: ", round(waic.pois$WAIC, digits=3)))
```


# Model 2: Bayesian single linear regression 
The results from models S and Sa, as well as the pairs plot, suggest that x3, %Biden, might be the only contributing covariate to residential rooftop PV adoption. Test that by trying a simple Bayesian linear regression with x3 as the sole covariate:

## Specify model
```{r}
linear_glm_x3 <- "
model {
  beta[1] ~ dnorm(B01, Vb1)
  beta[2] ~ dnorm(B02, Vb2)
  S ~ dgamma(s1, s2)      ## prior on precision
  
  for(i in 1:n) {
    mu[i] <- beta[1] + beta[2]*x[i]
    y[i] ~ dnorm(mu[i], S)
    like[i] <- dnorm(y[i], mu[i], S)
  }
}"
```

## MCMC Setup
```{r}
data1 <- list(y=dat$y, x=dat$x3)

# Specify priors
data1$B01 <- 0      ## priors on B1 means
data1$B02 <- 0      ## priors on B2 means
data1$Vb1 <- 0.001  ## priors on B1 variances
data1$Vb2 <- 0.001  ## priors on B2 variances
data1$s1  <- 0.001
data1$s2  <- 0.001
data1$n  <- length(data1$y) ## n = no. of observations; m = no. of covariates

# Initialize JAGS
j.lin_x3 <- jags.model(file=textConnection(linear_glm_x3),
                       data=data1, 
                       n.chains=3)
```

## Run MCMC
```{r}
# Run JAGS
jags.lin_x3 <- coda.samples(model=j.lin_x3, 
                          variable.names=c("beta[1]", "beta[2]", "S", "like"),
                          n.iter=30000)
```

## Diagnostics
```{r}
# Split MCMC output
lin_x3_split <- codaSplit(jags.lin_x3, "like")
plot(lin_x3_split[[2]])

# Remove burn-in
jags.burn_lin_x3 <- window(jags.lin_x3, start=2000)
out_burn_lin_x3  <- as.matrix(jags.burn_lin_x3) 
burn_lin_x3_split <- codaSplit(jags.burn_lin_x3, "like")

# Checking convergence & posterior densities
plot(burn_lin_x3_split[[2]])

# Brooks-Gelman-Rubin
GBR <- gelman.plot(burn_lin_x3_split[[2]])

# Effective sample size
effectiveSize(burn_lin_x3_split[[2]])
```

## Density plots
```{r}
out_lin_x3_split <- as.matrix(burn_lin_x3_split[[2]])

plot(density(out_lin_x3_split[,1]), main="Intercept", 
     sub="Density of MCMC samples for intercept term (linear model)", cex.sub=0.8) 
plot(density(out_lin_x3_split[,2]), main="Beta[1]", 
     sub="Density of MCMC samples for slope on %Biden term (linear model)", cex.sub=0.8)  
```

## Model Fit
```{r}
# DIC
dic.lin_x3 <- dic.samples(j.lin_x3, 1000, "pD")
dic.lin_x3 <- sum(dic.lin_x3$deviance) + sum(dic.lin_x3$penalty)

# WAIC
waic.lin_x3 <- WAIC(as.matrix(lin_x3_split[[1]]))

print(paste("DIC: ", round(dic.lin_x3, digits=3), " WAIC: ", round(waic.lin_x3$WAIC, digits=3)))
```

## Parameter Confidence Intervals
```{r}
cS.lin_x3 <- quantile(out_burn_lin_x3[,"S"], c(0.025, 0.975))        ## S 
c1.lin_x3 <- quantile(out_burn_lin_x3[,"beta[1]"], c(0.025, 0.975))  ## beta[1] (intercept)
c2.lin_x3 <- quantile(out_burn_lin_x3[,"beta[2]"], c(0.025, 0.975))  ## beta[2] (slope on x3, %Biden)
```

## Credible and Predictive Interval Plots
***REDO PLOT***
```{r}
niter <- 10000
xpred <- seq(0.3, 1.0, length=50)
npred <- length(xpred)

ypred <- matrix(NA, nrow=niter, ncol=npred)
ycred <- matrix(NA, nrow=niter, ncol=npred)

for(i in 1:niter) {
  Ey <- out_burn_lin_x3[i, "beta[1]"] + out_burn_lin_x3[i, "beta[2]"]*xpred
  ycred[i,] <- Ey
  ypred[i,] <- rnorm(npred, Ey, out_burn_lin_x3[, "S"])
}

ci.x3 <- apply(ycred, 2, quantile, c(0.025, 0.975), na.rm=TRUE)
pi.x3 <- apply(ypred, 2, quantile, c(0.025, 0.975), na.rm=TRUE)

plot(data1$x, data1$y,
     main="CI, PI Plots for Bayesian Poisson Model",
     xlab="x3, %Biden",
     ylab="N, adoptions")

lines(xpred, ci.x3[1,], col=3, lty=2)
lines(xpred, ci.x3[2,], col=3, lty=2)

lines(xpred, pi.x3[1,], col=2, lty=2)
lines(xpred, pi.x3[2,], col=2, lty=2)

legend(0.4, 800, legend=c("CI", "PI"), col=c(3, 2), lty=2, cex=0.8)
```
# Model 3: Bayesian single linear regression with errors in variables
Process model:
$$\mu_i = \beta_0 + \beta_1 x_i$$

General errors in variables data model:
$$y_i \sim Normal(\mu_i, S) \\ x_{i, observed} \sim Normal(\alpha_i x_i, \tau^2)$$

Parameter model:
$$\beta_i \sim Normal(B_{0i}, V_{bi}) \\ S \sim Gamma(s_1, s_2) \\ \alpha \sim Normal(a_0, V_a)$$

In this case, the American Community Survey (ACS) income data also reports Margins of Error (MOE) for each estimate, which can be fed directly into JAGS as precisions, instead of estimating with the alpha parameters:

## SE Calculations for errors in income data
```{r}
# Observation error
MOE <- PV$moeInc
SE  <- abs(MOE) / 1.645   ## source: US Census Bureau, 2009
```

## Specify Model 
```{r}
linear_glm_err <- "
model {
  beta[1] ~ dnorm(B01, Vb1)
  beta[2] ~ dnorm(B02, Vb2)
  
  S ~ dgamma(s1, s2)
  
  for(i in 1:n) {
    x[i] ~ dunif(X1, X2)
  }
  
  for(i in 1:n) {
    
    xo[i] ~ dnorm(x[i], tau[i])
    
    mu[i] <- beta[1] + beta[2]*x[i]
    y[i] ~ dnorm(mu[i], S)
    like[i] <- dnorm(y[i], mu[i], S)
  }
}"
```

## MCMC Setup
```{r}
datae <- list(y=dat$y, xo=dat$x3, tau=SE)

# Specify priors:
datae$B01 <- 0      ## priors on B1 means
datae$B02 <- 0      ## priors on B2 means
datae$Vb1 <- 0.001  ## priors on B1 variances
datae$Vb2 <- 0.001  ## priors on B2 variances
datae$s1  <- 0.001
datae$s2  <- 0.001
datae$X1  <- min(dat$x3)
datae$X2  <- max(dat$x3)
datae$n   <- length(datae$y)

# Initialize JAGS:
j.lin_err <- jags.model(file=textConnection(linear_glm_err),
                       data=datae,
                       n.chains=3)
```

```{r}
jags.lin_err <- coda.samples(model=j.lin_err,
                            variable.names=c("beta[1]", "beta[2]", "S", "xo", "like"),
                            n.iter=10000)
```

```{r}
out_err <- as.matrix(jags.lin_err)
sel.x <- grep("x", colnames(out_err))

plot(density(datae$xo), main="Observed incomes")
plot(density(out_err[,sel.x]), main="MCMC sampled incomes")
```

## Diagnostics
```{r}
# Split MCMC output
lin_err_split <- codaSplit(jags.lin_err, "like")
plot(lin_err_split[[2]])

# Effective sample size
effectiveSize(lin_err_split[[2]])
```

## Model Fit
```{r}
# DIC
dic.lin_err <- dic.samples(j.lin_err, 1000, "pD")
dic.lin_err <- sum(dic.lin_err$deviance) + sum(dic.lin_err$penalty)

# WAIC
waic.lin_err <- WAIC(as.matrix(lin_err_split[[1]]))

print(paste("DIC: ", round(dic.lin_err, digits=3), " WAIC: ", round(waic.lin_err$WAIC, digits=3)))
```

## Parameter Confidence Intervals
```{r}
cS.lin_he <- quantile(out_err[,"S"], c(0.025, 0.975))        ## S
c1.lin_he <- quantile(out_err[,"beta[1]"], c(0.025, 0.975))  ## beta[1] (intercept)
c2.lin_he <- quantile(out_err[,"beta[2]"], c(0.025, 0.975))  ## beta[2] (slope on x3, %Biden)
```


# Model 4: exponential time-series analysis

```{r}
inst <- read.csv("/home/lucia/bu/year4/semester2/EE509/project/ee509-project/data/ready/timeseries/timeseries.csv")

yr <- inst$year
y  <- inst$inst

yr <- append(yr, 2002, after=2)
y  <- append(y, "NA", after=2)
y  <- as.numeric(y)
```

## Specify model
```{r}
exp_model <- "
model {
  
  r ~ dnorm(r0, Vr)     ## prior on intrinsic growth rate
  tau ~ dgamma(t1, t2)  ## prior on process variance
  S ~ dgamma(s1, s2)    ## prior on observation error
  x[1] ~ dnorm(x0, Vx)  ## prior on initial x 
  
  for(t in 1:n) {
    y[t] ~ dnorm(x[t], tau)
  }
  
  for(t in 2:n) {
    mu[t] <- x[t-1] + r
    x[t] ~ dnorm(mu[t], S)
  }
}"
```

## MCMC Setup
```{r}
datat <- list(y=y, n=length(y))

# Specify priors
datat$r0 <- 0
datat$Vr <- 0.001
datat$x0 <- 1
datat$Vx <- 0.001
datat$t1 <- 0.001
datat$t2 <- 0.001
datat$s1 <- 0.001
datat$s2 <- 0.001

# Initial values for all state variables and latent X's
inits = list(x=y, r=0.8, tau=100, S=1)

# Run JAGS
j.exp <- jags.model(file=textConnection(exp_model),
                          data=datat,
                          inits=inits,
                          n.chains=3)
```

```{r}
jags.exp <- coda.samples(model=j.exp,
                         variable.names=c("x", "S", "r", "tau", "y[3]"),
                         n.iter=200000)

plot(jags.exp)
```

## Diagnostics
```{r}
jags.burn_exp <- window(jags.exp, start=10000)
GBR <- gelman.plot(jags.burn_exp)

effectiveSize(jags.burn_exp) 
```

Looks like tau needs more samples in order to converge, but just 200,000 is a big ask for my laptop.

## Parameter Confidence Intervals
```{r}
out_exp <- as.matrix(jags.burn_exp)

cS.exp <- quantile(out_exp[,"S"], c(0.025, 0.975))    ## S 
cr.exp <- quantile(out_exp[,"r"], c(0.025, 0.975))    ## r
ct.exp <- quantile(out_exp[,"tau"], c(0.025, 0.975))  ## tau
cy.exp <- quantile(out_exp[,"y[3]"], c(0.025, 0.975)) ## missing y
```

## Credible Interval Plots
```{r}
# Pulling out the x's
sel.x <- grep("x", colnames(out_exp))
x.e <- out_exp[, sel.x]

niter <- 10000
xpred <- seq(2000:2021)
npred <- length(xpred)

ycred <- matrix(NA, nrow=niter, ncol=npred)

for(i in 1:niter) {
  ycred[i,] <- x.e[i,] + out_exp[i, "r"]
}

ci.e <- apply(ycred, 2, quantile, c(0.025, 0.975))

plot(xpred, datat$y, main="Figure 3: CIs for time-series model")
lines(xpred, ci.e[1,], col=3, lty=2)
lines(xpred, ci.e[2,], col=3, lty=2)
```

## Missing Data
```{r}
plot(density(out_exp[,"y[3]"]), xlim=c(-100, 1000), main="Figure 4: Posterior for missing observation (2003)")
abline(v=mean(out_exp[,"y[3]"]), col=2, lty=2)
print(mean(out_exp[,"y[3]"]))

plot(density(out_exp[,"r"]), main="Figure 5: Posterior for growth rate")
abline(v=mean(out_exp[,"r"]), col=2, lty=2)
print(mean(out_exp[,"r"]))
```

## Model Fit
```{r}
# DIC
dic.exp <- dic.samples(j.exp, 1000, "pD")
dic.exp <- sum(dic.exp$deviance) + sum(dic.exp$penalty)

# WAIC
# TODO: add likelihood to model

print(paste("DIC: ", round(dic.exp, digits=3))) ##, " WAIC: "
```

# Results

Comparing the outputs of model 1 (simple Bayesian linear regression on 3 covariates), model 2 (Bayesian linear regression on 3 covariates with errors in income data), and model 3 (Bayesian linear regression on 1 covariate).

Just from WAIC and DIC scores, model 2 appears to perform better as a descriptor of rooftop PV adoption. It has a much lower DIC than both model 1 and model 3, but the WAIC scores were the same. However, since both models 1 and 2 arrived at very similar estimates for the parameter values and their 95% CIs, I question how much the covariates actually contribute to the observed values of rooftop PV adoption. This is curious, especially considering that in theory, model 2 should be able to model latent, "true" incomes as opposed to the highly error-prone reported income values, and one would expect higher incomes to be correlated with greater adoption because of the upfront and maintenance costs of rooftop PV systems. 

With the exception of x3, or %Biden, the covariates seem to have mild or very little effect on y (their means are at or around 0, with narrow CIs). betas[4], or the slope parameter on x3, suggests that a greater fraction of votes for Biden correlate with an increase in rooftop PV adoption. Perhaps x3 is thus the only significant covariate. 

Testing this assumption with model 3, which uses just voting data to predict adoption, is inconclusive. Model 3 arrived at the same parameter estimates as both models 1 and 2 for S, the intercept term, and the slope on voting, but performed worse according to DIC, despite having fewer parameters. The WAIC score was again the same as that for the other two models. 

Finally, model 4 (exponential time-series) is a departure from the previous regression models. Rather than exploring factors affecting residential rooftop solar adoption, the time-series models the change in the number of installations over time. Thus, there are no covariates. The results of this model (eg. DIC, parameter values) can't be compared to those of models 1-3.

Model 4 produced quite wide confidence intervals for almost all of its parameters, including negative values for the estimate of the missing observation in 2003. This may be partially because there is a steep drop in the number of installed PV systems starting in 2016, whereas previously the trend had been monotonically increasing. 

## Summary tables: models 1-3
```{r}
params <- c("S", "betas[1]", "betas[2]", "betas[3]", "betas[4]")

model1_vals <- c(mean(out_burn_lin_mv[,"S"]), 
                 mean(out_burn_lin_mv[,"betas[1]"]),
                 mean(out_burn_lin_mv[,"betas[2]"]),
                 mean(out_burn_lin_mv[,"betas[3]"]),
                 mean(out_burn_lin_mv[,"betas[4]"]))
model2_vals <- c(mean(out_burn_he[,"S"]), 
                 mean(out_burn_he[,"betas[1]"]),
                 mean(out_burn_he[,"betas[2]"]), 
                 mean(out_burn_he[,"betas[3]"]),
                 mean(out_burn_he[,"betas[4]"]))
model3_vals <- c(mean(out_burn_lin_x3[,"S"]),
                 mean(out_burn_lin_x3[,"betas[1]"]),
                 NA,
                 NA,
                 mean(out_burn_lin_x3[,"betas[2]"]))

model1_ci_l <- c(cS.lin_mv[1], c1.lin_mv[1], c2.lin_mv[1], c3.lin_mv[1], c4.lin_mv[1])
model1_ci_u <- c(cS.lin_mv[2], c1.lin_mv[2], c2.lin_mv[2], c3.lin_mv[2], c4.lin_mv[2])
model2_ci_l <- c(cS.lin_he[1], c1.lin_he[1], c2.lin_he[1], c3.lin_he[1], c4.lin_he[1])
model2_ci_u <- c(cS.lin_he[2], c1.lin_he[2], c2.lin_he[2], c3.lin_he[2], c4.lin_he[2])
model3_ci_l <- c(cS.lin_x3[1], c1.lin_x3[1], NA, NA, c2.lin_x3[1])
model3_ci_u <- c(cS.lin_x3[2], c1.lin_x3[2], NA, NA, c2.lin_x3[2])

res_df <- data.frame(params, model1_vals, model2_vals, model3_vals,
                     model1_ci_l, model1_ci_u, 
                     model2_ci_l, model2_ci_u,
                     model3_ci_l, model3_ci_u)

fit    <- c("DIC", "WAIC")
model1 <- c(dic.lin_mv, waic.lin_mv$WAIC)
model2 <- c(dic.lin_he, waic.lin_he$WAIC)
model3 <- c(dic.lin_x3, waic.lin_x3$WAIC)

fit_df <- data.frame(fit, model1, model2, model3)

knitr::kable(res_df, caption="Table 1: Parameter values for models 1, 2, and 3")

knitr::kable(fit_df, caption="Table 2: DIC and WAIC values for models 1, 2, and 3")
```

## Comparing param values visually
```{r}
MCMCplot(object=jags.burn_lin_mv,
         object2=jags.burn_lin_he,
         params=c("S", "betas[1]", "betas[2]", "betas[3]", "betas[4]"),
         offset=0.2,
         ISB=FALSE,
         exact=TRUE,
         main="Figure 6: Comparison of parameters for models 1 and 2")
```

## Summary tables: model 4
```{r}
params_t <- c("r", "S", "tau", "y[3]")

model4_vals <- c(mean(out_exp[,"r"]), mean(out_exp[,"S"]),
                 mean(out_exp[,"tau"]), mean(out_exp[,"y[3]"]))

model4_ci_l <- c(cS.exp[1], cr.exp[1], ct.exp[1], cy.exp[1])
model4_ci_u <- c(cS.exp[2], cr.exp[2], ct.exp[2], cy.exp[2])

res_t_df <- data.frame(params_t, model4_vals, model4_ci_l, model4_ci_u)

knitr::kable(res_t_df, caption="Table 3: Parameter values for time-series model")
```

TODO: 
1. CIs for lin_mv model
2. CIs for errors in variables model
3. CIs for single linear regression model