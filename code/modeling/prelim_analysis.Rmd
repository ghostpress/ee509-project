---
title: "EE 509 Project: Preliminary Analysis"
author: "Lucia Vilallonga"
output: html_notebook
---

# Background

3 models to fit: (1) Bayesian linear regression; (2) Bayesian linear regression with heteroskedasticity in income data; and (3) time-series analysis. Objective: describe and determine factors for adoption of residential rooftop solar systems in Massachusetts towns.

# Setup
## Libraries
```{r, echo=FALSE}
library(sf)             ## GIS data
library(rjags)          ## MCMC
library(MCMCvis)        ## Visualize MCMC outputs for particular params
library(LaplacesDemon)  ## WAIC
library(pdftools)       ## convert MCMCvis PDF output to image
library(imager)         ## show images from file
```

## Load and Format Data
```{r}
X <- st_read("/home/lucia/bu/year4/semester2/EE509/project/ee509-project/data/ready/X/X.shp")
y <- read.csv("/home/lucia/bu/year4/semester2/EE509/project/ee509-project/data/ready/y/y.csv")

# Join the datasets along the town axis
PV <- merge(X, y, by="TOWN")

# Format data for MCMC
# First model will not include spatial variables
# For now, just use the average income and education values (not sum/highest)
dat <- list(y=PV$totalInst, x1=PV$avgEd, x2=PV$avgInc, x3=PV$Biden.)
X <- model.matrix(~x1 + x2 + x3, data=dat)  ## prepends a column of 1s and puts xj into matrix X
```

# First model: Bayesian GLM with Poisson regression

Process model:
$$log(\lambda_i) = \boldsymbol{\beta} X_i$$
Data model:
$$y_i \sim Pois(\lambda_i)$$
Parameter model:
$$\beta \sim Normal(B_0, V_b)$$
Log-likelihood:
$$ln(L) = \sum_{i=1}^n y_i(\beta X_i) - \sum_{i=1}^ne^{\beta X_i}$$

## Specify Model
```{r}
poisson_glm <- "
model {
  beta ~ dmnorm(B0, Vb)  ## prior on betas

  for(i in 1:n) {
    log(lambda[i]) <- beta[1] + beta[2]*x[i]    ## process model
    y[i] ~ dpois(lambda[i])                     ## data model 
    like[i] <- y[i]*log(lambda[i]) - lambda[i]  ## log-likelihoods
  }
}"
```

Poisson regression doesn't seem to work; can't get the model to converge, even with upwards of 200,000 samples and playing around with initial values. The effective sample size is always in the single digits. Moving on to try a Bayesian linear model instead.

# Model 1a: Bayesian linear regression

Process model:
$$\mu_i = \beta X_i$$
Data model:
$$y_i \sim Normal(\mu_i, S)$$
Parameter model:
$$\beta \sim Normal(B_0, V_b) \\ S \sim Gamma(s_1, s_2)$$
## Specify Model
```{r}
linear_glm_mv <- "
model {
  betas ~ dmnorm(B0, Vb)  ## prior on betas
  S ~ dgamma(s1, s2)      ## prior on precision
  
  for(i in 1:n) {
    mu[i] <- X[i,] %*% betas
    y[i] ~ dnorm(mu[i], S)
    like[i] <- dnorm(y[i], mu[i], S)
  }
}"
```

## MCMC Setup
```{r}
datam <- list(y=dat$y, X=X)

# Specify priors
datam$B0 <- as.vector(c(0, 0, 0, 0))  ## priors on param.s means
datam$Vb <- solve(diag(10000, 4))     ## priors on param.s variances
datam$s1  <- 0.001
datam$s2  <- 0.001
datam$n  <- length(datam$y) ## n = no. of observations; m = no. of covariates

# Initialize JAGS
j.lin_mv <- jags.model(file=textConnection(linear_glm_mv),
                       data=datam, 
                       n.chains=3)
```

## Run MCMC
```{r}
# Run JAGS
jags.lin_mv <- coda.samples(model=j.lin_mv, 
                          variable.names=c("betas", "S", "like"),
                          n.iter=10000)

#out_lin_mv <- as.matrix(jags.lin_mv)
```

## Splitting JAGS output
Code source: Michael Dietze
```{r}
# Function to split JAGS output
codaSplit <- function(jags.out,pattern){
  out = list()
  mfit = as.matrix(jags.out,chains=TRUE)
  pat.cols = grep(pattern,colnames(mfit),fixed=TRUE)
  chain.col = which(colnames(mfit)=="CHAIN")
  out[[1]] = mat2mcmc.list(mfit[,c(chain.col,pat.cols)])
  out[[2]]   = mat2mcmc.list(mfit[,-pat.cols])
  return(out)
}

mat2mcmc.list <- function(w) {
  temp <- list()
  chain.col <- which(colnames(w) == "CHAIN")
  for (i in unique(w[, "CHAIN"])) {
    temp[[i]] <- coda:::as.mcmc(w[w[, "CHAIN"] == i, -chain.col])
  }
  return(as.mcmc.list(temp))
}
```

## Diagnostics
```{r}
# Split MCMC output
lin_mv_split <- codaSplit(jags.lin_mv, "like")
plot(lin_mv_split[[2]])

# Remove burn-in
jags.burn_lin_mv <- window(jags.lin_mv, start=500)
out_burn_lin_mv  <- as.matrix(jags.burn_lin_mv) 
jags.burn_lin_mv_split <- codaSplit(jags.burn_lin_mv, "like")

# Checking convergence & posterior densities
plot(jags.burn_lin_mv_split[[2]])

# Brooks-Gelman-Rubin
GBR <- gelman.plot(lin_mv_split[[2]])

# Effective sample size
effectiveSize(lin_mv_split[[2]])
```

## Density plots
```{r}
out_lin_mv_split <- as.matrix(lin_mv_split[[2]])

plot(density(out_lin_mv_split[,1]), main="Intercept", 
     sub="Density of MCMC samples for intercept term", cex.sub=0.8) 
plot(density(out_lin_mv_split[,2]), main="Beta[1]", 
     sub="Density of MCMC samples for slope on avgEd term", cex.sub=0.8)  
plot(density(out_lin_mv_split[,3]), main="Beta[2]", 
     sub="Density of MCMC samples for slope on avgInc", cex.sub=0.8) 
plot(density(out_lin_mv_split[,4]), main="Beta[3]", 
     sub="Density of MCMC samples for slope on %Biden", cex.sub=0.8)  
```

## Model Fit
```{r}
# DIC
dic.lin_mv <- dic.samples(j.lin_mv, 1000, "pD")
dic.lin_mv <- sum(dic.lin_mv$deviance) + sum(dic.lin_mv$penalty)

# WAIC
waic.lin_mv <- WAIC(as.matrix(lin_mv_split[[1]]))

print(paste("DIC: ", round(dic.lin_mv, digits=3), " WAIC: ", round(waic.lin_mv$WAIC, digits=3)))
```

## Parameter Confidence Intervals
```{r}
cS.lin_mv <- quantile(out_lin_mv_split[,"S"], c(0.025, 0.975))         ## S 
c1.lin_mv <- quantile(out_lin_mv_split[,"betas[1]"], c(0.025, 0.975))  ## beta[1] (intercept)
c2.lin_mv <- quantile(out_lin_mv_split[,"betas[2]"], c(0.025, 0.975))  ## beta[2] (slope on x1, avgEd)
c3.lin_mv <- quantile(out_lin_mv_split[,"betas[3]"], c(0.025, 0.975))  ## beta[3] (slope on x2, avgInc)
c4.lin_mv <- quantile(out_lin_mv_split[,"betas[4]"], c(0.025, 0.975))  ## beta[4] (slope on x3, %voBiden)
```

# Second Model: Bayesian linear regression with heteroskedasticity in income data

Process model:
$$\mu_i = \beta X_i$$

Data model:
$$y_i \sim Normal(\mu_i, S) \\ X_{inc, i, observed} \sim Normal(X_{inc, i}, \alpha_i X_{inc, i})$$

Parameter model:
$$\beta \sim Normal(B_0, V_b) \\ S \sim Gamma(s_1, s_2) \\ \alpha \sim Normal(a_0, V_a)$$

In this case, the American Community Survey (ACS) income data also reports Margins of Error (MOE) for each estimate, which can be fed directly into JAGS as precisions, instead of estimating with the alpha parameters:

## SE Calculations for heteroskedastic income data
```{r}
MOE <- PV$moeInc
SE  <- abs(MOE) / 1.645   ## source: US Census Bureau, 2009
```

## Specify Model 
```{r}
linear_glm_he <- "
model {
  betas ~ dmnorm(B0, Vb)  ## prior on betas
  #alpha ~ dlorm(a1, Va)  ## prior on X variance param. (zero-bound)
  S ~ dgamma(s1, s2)
  
  for(i in 1:n) {
    X[i,3] ~ dnorm(dummy_x3[i], SE[i])  ## income data is in the 3rd column of X
    x3.hat[i] <- X[i,3]
  }
  
  for(i in 1:n) {
    mu[i] <- X[i,] %*% betas
    
    #s[i] <- alpha*X[i,3]  
    #S[i] <- 1/s[i]^2
    
    y[i] ~ dnorm(mu[i], S)
    like[i] <- dnorm(y[i], mu[i], S)
  }
}"
```

## MCMC Setup
```{r}
datah <- list(y=dat$y, X=X, SE=SE)

# Create a dummy vector x3 for the income data:
datah$dummy_x3 <- datah$X[,3]

# Specify priors:
datah$B0 <- as.vector(c(0, 0, 0, 0))
datah$Vb <- solve(diag(10000, 4))
datah$s1 <- 0.001
datah$s2 <- 0.001
datah$n  <- length(datah$y)

# Initialize JAGS:
j.lin_he <- jags.model(file=textConnection(linear_glm_he),
                       data=datah,
                       n.chains=3)
```

```{r}
jags.lin_he <- coda.samples(model=j.lin_he,
                            variable.names=c("betas", "S", "x3.hat", "like"),
                            n.iter=10000)
```

```{r}
out_he <- as.matrix(jags.lin_he)

plot(density(datah$dummy_x3), main="Figure 1: Reported incomes")
plot(density(out_he[,356:705]), main="Figure 2: Sampled incomes using MOE")
```
## Diagnostics
```{r}
# Plots commented out below bc couldn't split MCMC object 2x, 
# so with like and x3.hat there are 705 plots total
#plot(jags.lin_he)  ## good convergence on betas, S
#GBR <- gelman.plot(jags.lin_he)  ## burn-in should be around 1000

# Burn-in:
jags.burn_lin_he <- window(jags.lin_he, start=1000)

# Using MCMCvis to get the trace plots of just S and betas
MCMCtrace(jags.burn_lin_he, 
          params=c("S", "betas[1]", "betas[2]", "betas[3]", "betas[4]"),
          ISB=FALSE,
          exact=TRUE)  ## outputs a PDF file in working directory

# Show trace plots:
pdf_convert("MCMCtrace.pdf", format="png")  ## convert to png file
knitr::include_graphics("/home/lucia/bu/year4/semester2/EE509/project/ee509-project/code/modeling/MCMCtrace_1.png")
knitr::include_graphics("/home/lucia/bu/year4/semester2/EE509/project/ee509-project/code/modeling/MCMCtrace_2.png")

#effectiveSize(jags.burn_lin_he)  ## >10,000 for S, betas
```

## Model Fit
```{r}
# DIC
dic.lin_he <- dic.samples(j.lin_he, 1000, "pD")
dic.lin_he <- sum(dic.lin_he$deviance) + sum(dic.lin_he$penalty)

# WAIC
lin_he_split <- codaSplit(jags.lin_he, "like")
waic.lin_he <- WAIC(as.matrix(lin_he_split[[1]]))

print(paste("DIC: ", round(dic.lin_he, digits=3), " WAIC: ", round(waic.lin_he$WAIC, digits=3)))
```

## Parameter Confidence Intervals
```{r}
out_burn_he <- as.matrix(jags.burn_lin_he)

cS.lin_he <- quantile(out_burn_he[,"S"], c(0.025, 0.975))         ## S
c1.lin_he <- quantile(out_burn_he[,"betas[1]"], c(0.025, 0.975))  ## beta[1] (intercept)
c2.lin_he <- quantile(out_burn_he[,"betas[2]"], c(0.025, 0.975))  ## beta[2] (slope on x1, avgEd)
c3.lin_he <- quantile(out_burn_he[,"betas[3]"], c(0.025, 0.975))  ## beta[3] (slope on x2, avgInc)
c4.lin_he <- quantile(out_burn_he[,"betas[4]"], c(0.025, 0.975))  ## beta[4] (slope on x3, %voBiden)
```

# Model 3: Bayesian linear regression with one covariate (%Biden)

The results from models 1 and 2 suggest that x3, %Biden, might be the only contributing covariate to residential rooftop PV adoption. Test that by trying a simple Bayesian linear regression with x4 as the sole covariate:

## Specify model
```{r}
linear_glm_x3 <- "
model {
  betas ~ dmnorm(B0, Vb)  ## prior on betas
  S ~ dgamma(s1, s2)      ## prior on precision
  
  for(i in 1:n) {
    mu[i] <- betas[1] + betas[2]*x[i]
    y[i] ~ dnorm(mu[i], S)
    like[i] <- dnorm(y[i], mu[i], S)
  }
}"
```

## MCMC Setup
```{r}
data1 <- list(y=dat$y, x=dat$x3)

# Specify priors
data1$B0 <- as.vector(c(0, 0))     ## priors on param.s means
data1$Vb <- solve(diag(10000, 2))  ## priors on param.s variances
data1$s1  <- 0.001
data1$s2  <- 0.001
data1$n  <- length(data1$y) ## n = no. of observations; m = no. of covariates

# Initialize JAGS
j.lin_x3 <- jags.model(file=textConnection(linear_glm_x3),
                       data=data1, 
                       n.chains=3)
```

## Run MCMC
```{r}
# Run JAGS
jags.lin_x3 <- coda.samples(model=j.lin_x3, 
                          variable.names=c("betas", "S", "like"),
                          n.iter=10000)
```

## Diagnostics
```{r}
# Split MCMC output
lin_x3_split <- codaSplit(jags.lin_x3, "like")
plot(lin_x3_split[[2]])

# Remove burn-in
jags.burn_lin_x3 <- window(jags.lin_x3, start=500)
out_burn_lin_x3  <- as.matrix(jags.burn_lin_x3) 
jags.burn_lin_x3_split <- codaSplit(jags.burn_lin_x3, "like")

# Checking convergence & posterior densities
plot(jags.burn_lin_x3_split[[2]])

# Brooks-Gelman-Rubin
GBR <- gelman.plot(lin_x3_split[[2]])

# Effective sample size
effectiveSize(lin_x3_split[[2]])
```
## Density plots
```{r}
out_lin_x3_split <- as.matrix(lin_x3_split[[2]])

plot(density(out_lin_x3_split[,1]), main="Intercept", 
     sub="Density of MCMC samples for intercept term", cex.sub=0.8) 
plot(density(out_lin_x3_split[,2]), main="Beta[1]", 
     sub="Density of MCMC samples for slope on %Biden term", cex.sub=0.8)  
```

## Model Fit
```{r}
# DIC
dic.lin_x3 <- dic.samples(j.lin_x3, 1000, "pD")
dic.lin_x3 <- sum(dic.lin_x3$deviance) + sum(dic.lin_x3$penalty)

# WAIC
waic.lin_x3 <- WAIC(as.matrix(lin_x3_split[[1]]))

print(paste("DIC: ", round(dic.lin_x3, digits=3), " WAIC: ", round(waic.lin_x3$WAIC, digits=3)))
```

## Parameter Confidence Intervals
```{r}
cS.lin_x3 <- quantile(out_lin_x3_split[,"S"], c(0.025, 0.975))         ## S 
c1.lin_x3 <- quantile(out_lin_x3_split[,"betas[1]"], c(0.025, 0.975))  ## beta[1] (intercept)
c2.lin_x3 <- quantile(out_lin_x3_split[,"betas[2]"], c(0.025, 0.975))  ## beta[2] (slope on x3, %Biden)
```

## Confidence Interval Plots
```{r}
niter <- 10000
xpred <- seq(0, 1, by=0.005)
npred <- length(xpred)

ycred <- matrix(NA, nrow=niter, ncol=npred)

for(i in 1:niter) {
  ycred[i,] <- out_burn_lin_x3[i, "betas[1]"] + out_burn_lin_x3[i, "betas[2]"]*xpred[i]
}

ci.x3 <- apply(ycred, 2, quantile, c(0.025, 0.975), na.rm=TRUE)

plot(data1$x, data1$y)
lines(xpred, ci.x3[1,], col=3, lty=2)
lines(xpred, ci.x3[2,], col=3, lty=2)
```
# Model 4: exponential time-series analysis

```{r}
inst <- read.csv("/home/lucia/bu/year4/semester2/EE509/project/ee509-project/data/ready/timeseries/timeseries.csv")

yr <- inst$year
y  <- inst$inst

yr <- append(yr, 2002, after=2)
y  <- append(y, "NA", after=2)
y  <- as.numeric(y)
```

## Specify model
```{r}
exp_model <- "
model {
  
  r ~ dnorm(r0, Vr)     ## prior on intrinsic growth rate
  tau ~ dgamma(t1, t2)  ## prior on process variance
  S ~ dgamma(s1, s2)    ## prior on observation error
  x[1] ~ dnorm(x0, Vx)  ## prior on initial x 
  
  for(t in 1:n) {
    y[t] ~ dnorm(x[t], tau)
  }
  
  for(t in 2:n) {
    mu[t] <- x[t-1] + r
    x[t] ~ dnorm(mu[t], S)
  }
}"
```

## MCMC Setup
```{r}
datat <- list(y=y, n=length(y))

# Specify priors
datat$r0 <- 0
datat$Vr <- 0.001
datat$x0 <- 1
datat$Vx <- 0.001
datat$t1 <- 0.001
datat$t2 <- 0.001
datat$s1 <- 0.001
datat$s2 <- 0.001

# Initial values for all state variables and latent X's
inits = list(x=y, r=0.8, tau=100, S=1)

# Run JAGS
j.exp <- jags.model(file=textConnection(exp_model),
                          data=datat,
                          inits=inits,
                          n.chains=3)
```

```{r}
jags.exp <- coda.samples(model=j.exp,
                         variable.names=c("x", "S", "r", "tau", "y[3]"),
                         n.iter=100000)

plot(jags.exp)
```

## Diagnostics

```{r}
GBR <- gelman.plot(jags.exp)

jags.burn_exp <- window(jags.exp, start=80000)

effectiveSize(jags.burn_exp) 
```

# Results

Comparing the outputs of model 1 (simple Bayesian linear regression on 3 covariates), model 2 (Bayesian linear regression on 3 covariates with heteroskedasticity in income data), and model 3 (Bayesian linear regression on 1 covariate).

Just from WAIC and DIC scores, model 2 appears to perform better as a descriptor of rooftop PV adoption. It has a much lower DIC than both model 1 and model 3, but the WAIC scores were the same. However, since both models 1 and 2 arrived at very similar estimates for the parameter values and their 95% CIs, I question how much the covariates actually contribute to rooftop PV adoption. This is curious, especially considering that in theory, model 2 should be able to model latent, "true" incomes as opposed to the highly error-prone reported income values, and one would expect higher incomes to be correlated with greater adoption because of the upfront and maintenance costs of rooftop PV systems. 

With the exception of x3, or %Biden, the covariates seem to have mild or very little effect on y (their means are at or around 0, with narrow CIs). betas[4], or the slope parameter on x3, suggests that a greater fraction of votes for Biden correlate with an increase in rooftop PV adoption. Perhaps x3 is thus the only significant covariate. 

Testing this assumption with model 3, which uses just voting data to predict adoption, is inconclusive. Model 3 arrived at the same parameter estimates as both models 1 and 2 for S, the intercept term, and the slope on voting, but performed worse according to DIC, despite having fewer parameters. The WAIC score was again the same as that for the other two models. 

## Summary tables
```{r}
params <- c("S", "betas[1]", "betas[2]", "betas[3]", "betas[4]")

model1_vals <- c(mean(out_burn_lin_mv[,"S"]), 
                 mean(out_burn_lin_mv[,"betas[1]"]),
                 mean(out_burn_lin_mv[,"betas[2]"]),
                 mean(out_burn_lin_mv[,"betas[3]"]),
                 mean(out_burn_lin_mv[,"betas[4]"]))
model2_vals <- c(mean(out_burn_he[,"S"]), 
                 mean(out_burn_he[,"betas[1]"]),
                 mean(out_burn_he[,"betas[2]"]), 
                 mean(out_burn_he[,"betas[3]"]),
                 mean(out_burn_he[,"betas[4]"]))
model3_vals <- c(mean(out_burn_lin_x3[,"S"]),
                 mean(out_burn_lin_x3[,"betas[1]"]),
                 NA,
                 NA,
                 mean(out_burn_lin_x3[,"betas[2]"]))

model1_ci_l <- c(cS.lin_mv[1], c1.lin_mv[1], c2.lin_mv[1], c3.lin_mv[1], c4.lin_mv[1])
model1_ci_u <- c(cS.lin_mv[2], c1.lin_mv[2], c2.lin_mv[2], c3.lin_mv[2], c4.lin_mv[2])
model2_ci_l <- c(cS.lin_he[1], c1.lin_he[1], c2.lin_he[1], c3.lin_he[1], c4.lin_he[1])
model2_ci_u <- c(cS.lin_he[2], c1.lin_he[2], c2.lin_he[2], c3.lin_he[2], c4.lin_he[2])
model3_ci_l <- c(cS.lin_x3[1], c1.lin_x3[1], NA, NA, c2.lin_x3[1])
model3_ci_u <- c(cS.lin_x3[2], c1.lin_x3[2], NA, NA, c2.lin_x3[2])

res_df <- data.frame(params, model1_vals, model2_vals, model3_vals,
                     model1_ci_l, model1_ci_u, 
                     model2_ci_l, model2_ci_u,
                     model3_ci_l, model3_ci_u)

fit    <- c("DIC", "WAIC")
model1 <- c(dic.lin_mv, waic.lin_mv$WAIC)
model2 <- c(dic.lin_he, waic.lin_he$WAIC)
model3 <- c(dic.lin_x3, waic.lin_x3$WAIC)

fit_df <- data.frame(fit, model1, model2, model3)

knitr::kable(res_df, caption="Table 1: Parameter values for models 1, 2, and 3")

knitr::kable(fit_df, caption="Table 2: DIC and WAIC values for models 1, 2, and 3")
```

## Plotting param values
```{r}
MCMCplot(object=jags.burn_lin_mv,
         object2=jags.burn_lin_he,
         params=c("S", "betas[1]", "betas[2]", "betas[3]", "betas[4]"),
         offset=0.2,
         ISB=FALSE,
         exact=TRUE,
         main="Figure 3: Comparison of parameters for models 1 and 2")
```


TODO: 
1. CIs for lin_mv model
2. CIs for heteroskedastic model
3. CIs for single linear regression model
4. model 3: time-series